# 工作流程

## 准备部分
1. 由于要进行收集的资料是关于 “肯德基“ 和 ”疯狂星期四“ 的，构建的大概工作流程是先使用搜索引擎对关键词进行搜索，再使用 `selenium` 进行模拟浏览器控制， `lxml` 来解析页面的 `html` ， 从而收集到想要的文件资料。
2. 确定了技术选型之后选择采用 `json` 格式来储存资料。

## 实现部分
1. 安装了 `selenium`，`lxml` 以及所需要的工具，例如 `chromedriver` 。
2. 按照准备好的方式，使用 google 新闻搜索”KFC“ + “疯狂星期四”两个关键词，再对搜索结果顺序访问，提取`html`中的文字信息。
3. 使用 `json` 格式化输出。

## 修改部分
1. 发现有些页面存在页眉页脚以及联系方式等无关内容，进行删除。
2. 删除了一些无意义的字符，例如 `\n` ， `&nbsp` 等。
3. 对于搜索到的与 “肯德基” 、 “疯狂星期四” 无关的文章进行了筛选。

-----

# ligen131 工作流程

按照教程配置虚拟机和 Hadoop 集群。

